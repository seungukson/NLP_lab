{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ...train.txt 내용\n",
    "1 Mary moved to the bathroom.<br>\n",
    "2 John went to the hallway.<br>\n",
    "3 Where is Mary? (tab)bathroom(tab)1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train observations: 10000 Test observations: 1000\n"
     ]
    }
   ],
   "source": [
    "def get_data(infile):\n",
    "    stories, questions, answers = [], [], []\n",
    "    story_text = []\n",
    "    fin = open(infile, \"r\") \n",
    "    for line in fin:\n",
    "        line = line.strip()                # strip() : 양쪽 끝에 있는 공백, \\t, \\n 제거\n",
    "        lno, text = line.split(\" \", 1)     # 맨 앞의 라인 번호 분리\n",
    "        if \"\\t\" in text:                   # 세 번째 문장에는 \\t가 두개 있음.\n",
    "            question, answer, _ = text.split(\"\\t\")\n",
    "            stories.append(story_text)     # 처음 두 문장\n",
    "            questions.append(question)     # 세 번째 문장의 질문\n",
    "            answers.append(answer)         # 세 번째 문장의 답변\n",
    "            story_text = []\n",
    "        else:\n",
    "            story_text.append(text)        # 처음 두 문장이 들어감\n",
    "    fin.close()\n",
    "    return stories, questions, answers\n",
    "\n",
    "# get the data\n",
    "data_train = get_data(\"qa1_single-supporting-fact_train.txt\")\n",
    "data_test = get_data(\"qa1_single-supporting-fact_test.txt\")\n",
    "\n",
    "print(\"Train observations:\",len(data_train[0]),\"Test observations:\", len(data_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 에피소딕 스토리, 질문(Q), 답변(A) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스토리 =  ['Mary moved to the bathroom.', 'John went to the hallway.']\n",
      "질  문 =  Where is Mary? \n",
      "답  변 =  bathroom\n"
     ]
    }
   ],
   "source": [
    "print(\"스토리 = \", data_train[0][0])\n",
    "print(\"질  문 = \", data_train[1][0])\n",
    "print(\"답  변 = \", data_train[2][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Vocab dictionary from Train & Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 22\n",
      "{'to': 1, 'the': 2, '.': 3, 'where': 4, 'is': 5, '?': 6, 'went': 7, 'john': 8, 'sandra': 9, 'mary': 10, 'daniel': 11, 'bathroom': 12, 'office': 13, 'garden': 14, 'hallway': 15, 'kitchen': 16, 'bedroom': 17, 'journeyed': 18, 'travelled': 19, 'back': 20, 'moved': 21, 'PAD': 0}\n"
     ]
    }
   ],
   "source": [
    "dictnry = collections.Counter()\n",
    "for stories, questions, answers in [data_train, data_test]:\n",
    "    for story in stories:\n",
    "        for sent in story:\n",
    "            for word in nltk.word_tokenize(sent):\n",
    "                dictnry[word.lower()] += 1\n",
    "                \n",
    "    for question in questions:\n",
    "        for word in nltk.word_tokenize(question):\n",
    "            dictnry[word.lower()] += 1\n",
    "            \n",
    "    for answer in answers:\n",
    "        for word in nltk.word_tokenize(answer):\n",
    "            dictnry[word.lower()] += 1\n",
    "\n",
    "word2indx = {w:(i+1) for i,(w,_) in enumerate(dictnry.most_common())}\n",
    "\n",
    "word2indx[\"PAD\"] = 0\n",
    "indx2word = {v:k for k,v in word2indx.items()}\n",
    "\n",
    "vocab_size = len(word2indx)\n",
    "print(\"vocabulary size:\",len(word2indx))\n",
    "print(word2indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute max sequence length for each entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story maximum length: 14 Question maximum length: 4\n"
     ]
    }
   ],
   "source": [
    "story_maxlen = 0\n",
    "question_maxlen = 0\n",
    "\n",
    "for stories, questions, answers in [data_train, data_test]:\n",
    "    for story in stories:\n",
    "        story_len = 0\n",
    "        for sent in story:\n",
    "            swords = nltk.word_tokenize(sent)\n",
    "            story_len += len(swords)\n",
    "        if story_len > story_maxlen:\n",
    "            story_maxlen = story_len\n",
    "            \n",
    "    for question in questions:\n",
    "        question_len = len(nltk.word_tokenize(question))\n",
    "        if question_len > question_maxlen:\n",
    "            question_maxlen = question_len\n",
    "            \n",
    "print (\"Story maximum length:\",story_maxlen,\"Question maximum length:\",question_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Dense, Dropout, Permute\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import add, concatenate, dot\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting data into Vectorized form\n",
    "Xstrain[0] = [0,0,8,21,1,2,12,3,9,7,1,2,13,3]   - 14개<br>\n",
    "Xqtrain[0] = [4,5,8,6] - 4개<br>\n",
    "Ytrain[0] = [0,0,0,0,...0,1,0,0,0,]   - 22개의 one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John travelled to the hallway.', 'Mary journeyed to the bathroom.']\n",
      "[[8, 19, 1, 2, 15, 3], [10, 18, 1, 2, 12, 3]]\n",
      "[8, 19, 1, 2, 15, 3, 10, 18, 1, 2, 12, 3]\n"
     ]
    }
   ],
   "source": [
    "# list of list 연습\n",
    "for story, question, answer in zip(stories, questions, answers):\n",
    "    xs = [[word2indx[w.lower()] for w in nltk.word_tokenize(s)] for s in story]\n",
    "    print(story)\n",
    "    print(xs)\n",
    "    xs = list(itertools.chain.from_iterable(xs))\n",
    "    print(xs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train story (10000, 14) Train question (10000, 4) Train answer (10000, 22)\n",
      "Test story (1000, 14) Test question (1000, 4) Test answer (1000, 22)\n"
     ]
    }
   ],
   "source": [
    "def data_vectorization(data, word2indx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [[word2indx[w.lower()] for w in nltk.word_tokenize(s)] for s in story]\n",
    "        xs = list(itertools.chain.from_iterable(xs))   # 2개 스토리를 하나로 합친다\n",
    "        xq = [word2indx[w.lower()] for w in nltk.word_tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2indx[answer.lower()])\n",
    "        \n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           np_utils.to_categorical(Y, num_classes=len(word2indx))\n",
    "\n",
    "Xstrain, Xqtrain, Ytrain = data_vectorization(data_train, word2indx, story_maxlen, question_maxlen)\n",
    "Xstest, Xqtest, Ytest = data_vectorization(data_test, word2indx, story_maxlen, question_maxlen)\n",
    "\n",
    "print(\"Train story\",Xstrain.shape,\"Train question\", Xqtrain.shape,\"Train answer\", Ytrain.shape)\n",
    "print( \"Test story\",Xstest.shape, \"Test question\",Xqtest.shape, \"Test answer\",Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, 10, 21,  1,  2, 12,  3,  8,  7,  1,  2, 15,  3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xstrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 14, 128)      2816        input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 4, 128)       2816        input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 14, 128)      0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 4, 128)       0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 14, 4)        88          input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_8 (Dot)                     (None, 14, 4)        0           dropout_19[0][0]                 \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 14, 4)        0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 4)        0           dot_8[0][0]                      \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 4, 14)        0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 142)       0           permute_1[0][0]                  \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           52992       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 64)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 22)           1430        dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 22)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 60,142\n",
      "Trainable params: 60,142\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "LATENT_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "# Inputs\n",
    "story_input = Input(shape=(story_maxlen,))\n",
    "question_input = Input(shape=(question_maxlen,))\n",
    "\n",
    "# Story encoder embedding\n",
    "story_encoder = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_SIZE,\n",
    "                         input_length=story_maxlen)(story_input)\n",
    "story_encoder = Dropout(rate = 0.2)(story_encoder)\n",
    "\n",
    "# Question encoder embedding\n",
    "question_encoder = Embedding(input_dim=vocab_size,output_dim=EMBEDDING_SIZE,\n",
    "                            input_length=question_maxlen)(question_input)\n",
    "question_encoder = Dropout(rate = 0.3)(question_encoder)\n",
    "\n",
    "# Match between story and question\n",
    "match = dot([story_encoder, question_encoder], axes=[2,2])\n",
    "\n",
    "# Encode story into vector space of question\n",
    "story_encoder_c = Embedding(input_dim=vocab_size,output_dim=question_maxlen,\n",
    "                           input_length=story_maxlen)(story_input)\n",
    "story_encoder_c = Dropout(rate = 0.3)(story_encoder_c)\n",
    "\n",
    "# Combine match and story vectors\n",
    "response = add([match, story_encoder_c])\n",
    "response = Permute((2, 1))(response)\n",
    "\n",
    "# Combine response and question vectors to answers space\n",
    "answer = concatenate([response, question_encoder], axis=-1)\n",
    "answer = LSTM(LATENT_SIZE)(answer)\n",
    "answer = Dropout(rate = 0.2)(answer)\n",
    "answer = Dense(vocab_size)(answer)\n",
    "output = Activation(\"softmax\")(answer)\n",
    "\n",
    "model = Model(inputs=[story_input, question_input], outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/40\n",
      "10000/10000 [==============================] - 6s 643us/step - loss: 1.9876 - acc: 0.2044 - val_loss: 1.6515 - val_acc: 0.2970\n",
      "Epoch 2/40\n",
      "10000/10000 [==============================] - 2s 233us/step - loss: 1.6603 - acc: 0.2660 - val_loss: 1.6346 - val_acc: 0.2670\n",
      "Epoch 3/40\n",
      "10000/10000 [==============================] - 2s 230us/step - loss: 1.5537 - acc: 0.3859 - val_loss: 1.4456 - val_acc: 0.4930\n",
      "Epoch 4/40\n",
      "10000/10000 [==============================] - 2s 235us/step - loss: 1.4035 - acc: 0.5068 - val_loss: 1.3728 - val_acc: 0.5270\n",
      "Epoch 5/40\n",
      "10000/10000 [==============================] - 2s 232us/step - loss: 1.3445 - acc: 0.5204 - val_loss: 1.3469 - val_acc: 0.5270\n",
      "Epoch 6/40\n",
      "10000/10000 [==============================] - 2s 235us/step - loss: 1.3074 - acc: 0.5237 - val_loss: 1.3168 - val_acc: 0.5210\n",
      "Epoch 7/40\n",
      "10000/10000 [==============================] - 2s 232us/step - loss: 1.2766 - acc: 0.5227 - val_loss: 1.2906 - val_acc: 0.5280\n",
      "Epoch 8/40\n",
      "10000/10000 [==============================] - 2s 233us/step - loss: 1.2568 - acc: 0.5248 - val_loss: 1.2801 - val_acc: 0.5150\n",
      "Epoch 9/40\n",
      "10000/10000 [==============================] - 2s 235us/step - loss: 1.2366 - acc: 0.5309 - val_loss: 1.2457 - val_acc: 0.5350\n",
      "Epoch 10/40\n",
      "10000/10000 [==============================] - 2s 232us/step - loss: 1.0643 - acc: 0.6532 - val_loss: 0.8706 - val_acc: 0.7490\n",
      "Epoch 11/40\n",
      "10000/10000 [==============================] - 2s 237us/step - loss: 0.7140 - acc: 0.7803 - val_loss: 0.6324 - val_acc: 0.7580\n",
      "Epoch 12/40\n",
      "10000/10000 [==============================] - 2s 238us/step - loss: 0.5628 - acc: 0.7873 - val_loss: 0.5661 - val_acc: 0.7570\n",
      "Epoch 13/40\n",
      "10000/10000 [==============================] - 2s 232us/step - loss: 0.5169 - acc: 0.7892 - val_loss: 0.5484 - val_acc: 0.7550\n",
      "Epoch 14/40\n",
      "10000/10000 [==============================] - 2s 233us/step - loss: 0.4965 - acc: 0.7888 - val_loss: 0.5366 - val_acc: 0.7570\n",
      "Epoch 15/40\n",
      "10000/10000 [==============================] - 2s 233us/step - loss: 0.4849 - acc: 0.7915 - val_loss: 0.5360 - val_acc: 0.7530\n",
      "Epoch 16/40\n",
      "10000/10000 [==============================] - 2s 228us/step - loss: 0.4811 - acc: 0.7919 - val_loss: 0.5365 - val_acc: 0.7540\n",
      "Epoch 17/40\n",
      "10000/10000 [==============================] - 2s 232us/step - loss: 0.4784 - acc: 0.7932 - val_loss: 0.5348 - val_acc: 0.7500\n",
      "Epoch 18/40\n",
      "10000/10000 [==============================] - 2s 228us/step - loss: 0.4724 - acc: 0.7924 - val_loss: 0.5345 - val_acc: 0.7530\n",
      "Epoch 19/40\n",
      "10000/10000 [==============================] - 2s 228us/step - loss: 0.4688 - acc: 0.7933 - val_loss: 0.5281 - val_acc: 0.7620\n",
      "Epoch 20/40\n",
      "10000/10000 [==============================] - 2s 232us/step - loss: 0.4699 - acc: 0.7931 - val_loss: 0.5267 - val_acc: 0.7650\n",
      "Epoch 21/40\n",
      "10000/10000 [==============================] - 2s 228us/step - loss: 0.4683 - acc: 0.7946 - val_loss: 0.5331 - val_acc: 0.7550\n",
      "Epoch 22/40\n",
      "10000/10000 [==============================] - 2s 232us/step - loss: 0.4637 - acc: 0.7972 - val_loss: 0.5289 - val_acc: 0.7620\n",
      "Epoch 23/40\n",
      "10000/10000 [==============================] - 2s 228us/step - loss: 0.4601 - acc: 0.7992 - val_loss: 0.5326 - val_acc: 0.7540\n",
      "Epoch 24/40\n",
      "10000/10000 [==============================] - 2s 228us/step - loss: 0.4601 - acc: 0.8032 - val_loss: 0.5321 - val_acc: 0.7610\n",
      "Epoch 25/40\n",
      "10000/10000 [==============================] - 2s 229us/step - loss: 0.4599 - acc: 0.8005 - val_loss: 0.5344 - val_acc: 0.7610\n",
      "Epoch 26/40\n",
      "10000/10000 [==============================] - 2s 228us/step - loss: 0.4578 - acc: 0.8044 - val_loss: 0.5285 - val_acc: 0.7690\n",
      "Epoch 27/40\n",
      "10000/10000 [==============================] - 2s 228us/step - loss: 0.4570 - acc: 0.8038 - val_loss: 0.5291 - val_acc: 0.7650\n",
      "Epoch 28/40\n",
      "10000/10000 [==============================] - 2s 230us/step - loss: 0.4544 - acc: 0.8044 - val_loss: 0.5294 - val_acc: 0.7680\n",
      "Epoch 29/40\n",
      "10000/10000 [==============================] - 2s 227us/step - loss: 0.4517 - acc: 0.8074 - val_loss: 0.5326 - val_acc: 0.7700\n",
      "Epoch 30/40\n",
      "10000/10000 [==============================] - 2s 225us/step - loss: 0.4492 - acc: 0.8079 - val_loss: 0.5404 - val_acc: 0.7600\n",
      "Epoch 31/40\n",
      "10000/10000 [==============================] - 2s 229us/step - loss: 0.4483 - acc: 0.8073 - val_loss: 0.5328 - val_acc: 0.7660\n",
      "Epoch 32/40\n",
      "10000/10000 [==============================] - 2s 225us/step - loss: 0.4449 - acc: 0.8147 - val_loss: 0.5483 - val_acc: 0.7460\n",
      "Epoch 33/40\n",
      "10000/10000 [==============================] - 2s 225us/step - loss: 0.4467 - acc: 0.8130 - val_loss: 0.5400 - val_acc: 0.7490\n",
      "Epoch 34/40\n",
      "10000/10000 [==============================] - 2s 228us/step - loss: 0.4421 - acc: 0.8127 - val_loss: 0.5400 - val_acc: 0.7630\n",
      "Epoch 35/40\n",
      "10000/10000 [==============================] - 2s 223us/step - loss: 0.4398 - acc: 0.8139 - val_loss: 0.5415 - val_acc: 0.7700\n",
      "Epoch 36/40\n",
      "10000/10000 [==============================] - 2s 225us/step - loss: 0.4376 - acc: 0.8186 - val_loss: 0.5392 - val_acc: 0.7680\n",
      "Epoch 37/40\n",
      "10000/10000 [==============================] - 2s 222us/step - loss: 0.4374 - acc: 0.8178 - val_loss: 0.5394 - val_acc: 0.7730\n",
      "Epoch 38/40\n",
      "10000/10000 [==============================] - 2s 223us/step - loss: 0.4339 - acc: 0.8165 - val_loss: 0.5450 - val_acc: 0.7580\n",
      "Epoch 39/40\n",
      "10000/10000 [==============================] - 2s 226us/step - loss: 0.4310 - acc: 0.8207 - val_loss: 0.5533 - val_acc: 0.7640\n",
      "Epoch 40/40\n",
      "10000/10000 [==============================] - 2s 223us/step - loss: 0.4307 - acc: 0.8215 - val_loss: 0.5512 - val_acc: 0.7620\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([Xstrain, Xqtrain], [Ytrain], batch_size=BATCH_SIZE, \n",
    "                    epochs=NUM_EPOCHS, validation_data=([Xstest, Xqtest], [Ytest]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot accuracy and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Episodic Memory Q & A Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"r\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get predictions of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.762"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)\n",
    "accuracy_score(ytest, ytest_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Random questions and predict answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sandra went to the garden . john went to the garden . where is mary ? garden bathroom\n",
      "mary moved to the garden . daniel went back to the office . where is mary ? garden garden\n",
      "mary journeyed to the bedroom . sandra travelled to the hallway . where is john ? bedroom bedroom\n",
      "mary went to the kitchen . john journeyed to the kitchen . where is mary ? kitchen kitchen\n",
      "john journeyed to the hallway . john journeyed to the bedroom . where is john ? bedroom bedroom\n",
      "daniel went back to the hallway . mary went to the hallway . where is mary ? hallway hallway\n",
      "john journeyed to the bedroom . john went back to the hallway . where is mary ? garden bathroom\n",
      "sandra moved to the garden . daniel went back to the bedroom . where is sandra ? garden garden\n",
      "mary went to the bathroom . sandra moved to the garden . where is sandra ? garden garden\n",
      "john went back to the bathroom . daniel moved to the hallway . where is daniel ? hallway hallway\n"
     ]
    }
   ],
   "source": [
    "NUM_DISPLAY = 10\n",
    "   \n",
    "for i in random.sample(range(Xstest.shape[0]),NUM_DISPLAY):\n",
    "    story = \" \".join([indx2word[x] for x in Xstest[i].tolist() if x != 0])\n",
    "    question = \" \".join([indx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = indx2word[ytest[i]]\n",
    "    prediction = indx2word[ytest_[i]]\n",
    "    print(story, question, label, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'john went back to the bathroom . daniel moved to the hallway .'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'where is daniel ?'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
