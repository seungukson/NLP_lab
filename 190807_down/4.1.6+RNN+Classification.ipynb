{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.6 재현 신경망(Recurrent Neural Network) 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "\n",
    "TRAIN_INPUT_DATA = 'train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.load(open(DATA_IN_PATH + TRAIN_INPUT_DATA, 'rb'))\n",
    "label_data = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA, 'rb'))\n",
    "prepro_configs = None\n",
    "\n",
    "with open(DATA_IN_PATH + DATA_CONFIGS, 'r') as f:\n",
    "    prepro_configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.1\n",
    "RANDOM_SEED = 13371447\n",
    "\n",
    "train_input, test_input, train_label, test_label = train_test_split(input_data, label_data, \n",
    "                                                                    test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   12    12    12     5   182  2790   653  5372  3893    84   457  1806\n",
      "   308  1927    46  1101    84  6665  2514  3083    33   259   137    31\n",
      "   254   354  3987   792   691   921 37399  2184   335   208   398   481\n",
      "     6   118  1685    26 22324  2409  2110  1021   576  1584 17059    66\n",
      "  1089   163     3    11  2790  4061     2    66  2444  2144    39    61\n",
      "    91     6 11029   118  1535  1248  7824   441  5531    20   344   458\n",
      "   423   122  2773 19812  1161   164   925    57  1101   220   285  1059\n",
      "  5765   316  1927   234    78   425   964   704   616  1443   183  1030\n",
      "    55  2363  1232     2   227  2330   975  1363  9361    22   183     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "174\n"
     ]
    }
   ],
   "source": [
    "print(train_input[0])\n",
    "print(len(train_input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "def mapping_fn(X, Y):\n",
    "    inputs, labels = {'x': X}, Y\n",
    "    return inputs, labels\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((train_input, train_label))\n",
    "    dataset = dataset.shuffle(buffer_size=50000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat(count=NUM_EPOCHS)\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((test_input, test_label))\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    dataset = dataset.batch(BATCH_SIZE * 2)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = prepro_configs['vocab_size']+1\n",
    "WORD_EMBEDDING_DIM = 10\n",
    "HIDDEN_STATE_DIM = 10\n",
    "DENSE_FEATURE_DIM = 10\n",
    "\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74065 74066\n"
     ]
    }
   ],
   "source": [
    "print(len(prepro_configs['vocab']), VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    # RNN part with stacked RNN\n",
    "    embedding_layer = tf.keras.layers.Embedding(VOCAB_SIZE, WORD_EMBEDDING_DIM)(features['x'])\n",
    "    embedding_layer = tf.keras.layers.Dropout(0.2)(embedding_layer)\n",
    "    \n",
    "    #rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) for size in [HIDDEN_STATE_DIM, HIDDEN_STATE_DIM]]\n",
    "    #multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "    \n",
    "    rnn_layers = tf.nn.rnn_cell.LSTMCell(HIDDEN_STATE_DIM)\n",
    "    multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_layers] * 2)\n",
    "    \n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=multi_rnn_cell, inputs=embedding_layer, dtype=tf.float32)\n",
    "    \n",
    "    # feed-forward part\n",
    "    outputs = tf.keras.layers.Dropout(0.2)(outputs)\n",
    "    hidden_layer = tf.keras.layers.Dense(DENSE_FEATURE_DIM, activation=tf.nn.tanh)(outputs[:,-1,:])\n",
    "    hidden_layer = tf.keras.layers.Dropout(0.2)(hidden_layer)\n",
    "    logits = tf.keras.layers.Dense(1)(hidden_layer)\n",
    "    logits = tf.squeeze(logits, axis=-1)\n",
    "    \n",
    "    sigmoid_logits = tf.nn.sigmoid(logits)\n",
    "    \n",
    "    if PREDICT:\n",
    "        predictions = {'sentiment': sigmoid_logits}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
    "    \n",
    "    if EVAL:\n",
    "        accuracy = tf.metrics.accuracy(labels, tf.round(sigmoid_logits))\n",
    "        eval_metric_ops = {'acc': accuracy}\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "    \n",
    "    if TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, train_op=train_op, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './data_out/checkpoint/rnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000029BE756F160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "est = tf.estimator.Estimator(model_fn=model_fn, model_dir=DATA_OUT_PATH + 'checkpoint/rnn') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-8-eec3122bf7a7>:13: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-eec3122bf7a7>:14: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n",
      "WARNING:tensorflow:From <ipython-input-8-eec3122bf7a7>:16: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./data_out/checkpoint/rnn\\model.ckpt-2816\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2816 into ./data_out/checkpoint/rnn\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.044755813, step = 2817\n",
      "INFO:tensorflow:global_step/sec: 5.35343\n",
      "INFO:tensorflow:loss = 0.1602575, step = 2917 (18.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.38782\n",
      "INFO:tensorflow:loss = 0.2618324, step = 3017 (15.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.38284\n",
      "INFO:tensorflow:loss = 0.13984364, step = 3117 (15.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.36826\n",
      "INFO:tensorflow:loss = 0.12722173, step = 3217 (15.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.43179\n",
      "INFO:tensorflow:loss = 0.12206723, step = 3317 (15.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.44967\n",
      "INFO:tensorflow:loss = 0.08829208, step = 3417 (15.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.3714\n",
      "INFO:tensorflow:loss = 0.14306933, step = 3517 (15.680 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3520 into ./data_out/checkpoint/rnn\\model.ckpt.\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Loss for final step: 0.028389156.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x29be756b860>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-08-06T13:15:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./data_out/checkpoint/rnn\\model.ckpt-3520\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-08-06-13:15:46\n",
      "INFO:tensorflow:Saving dict for global step 3520: acc = 0.8588, global_step = 3520, loss = 0.44678202\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3520: ./data_out/checkpoint/rnn\\model.ckpt-3520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8588, 'loss': 0.44678202, 'global_step': 3520}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캐글 평가 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data_out/'\n",
    "TEST_INPUT_DATA = 'test_input.npy'\n",
    "TEST_ID_DATA = 'test_id.npy'\n",
    "\n",
    "test_input_data = np.load(open(DATA_IN_PATH + TEST_INPUT_DATA, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\":test_input_data}, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-9-eec3122bf7a7>:13: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-9-eec3122bf7a7>:14: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n",
      "WARNING:tensorflow:From <ipython-input-9-eec3122bf7a7>:16: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./data_out/checkpoint/rnn\\model.ckpt-2816\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array([p['sentiment'] for p in est.predict(input_fn=predict_input_fn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = np.load(open(DATA_IN_PATH + TEST_ID_DATA, 'rb'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\"12311_10\"', '\"8348_2\"', '\"5828_4\"', ..., '\"2531_1\"', '\"7772_8\"',\n",
       "       '\"11465_10\"'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "output = pd.DataFrame(data={\"id\": list(test_id), \"sentiment\":list(np.round(predictions))} )\n",
    "output.to_csv(DATA_OUT_PATH + 'movie_review_result_rnn.csv', index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
